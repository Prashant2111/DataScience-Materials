{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What are decision trees? What are the different types of decision trees?\n",
    "\n",
    "Decision Trees are machine learning technique for classification and regression. They are capable of discovering complex realtion between variables and making predictions on new data.Types of decision trees are ID3, C4.5, CART,conditional inference trees. Different algorithms use different metrics to determine both the variable to partition and  where to create the partition. Some of the more popular metrics used are Gini Impurity and Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What are weak learners?\n",
    "\n",
    "A weak learner is just one which performs relatively poorly, its accuracy is above average, but just barely. It is computationally simple. Weak learner also implies that many types of the algorithm can be grouped (boosting, bagging, etc) together to create a strong ensemble learner.Example of a Weak Learner is  a one-level decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. As compared to an individual model, are ensemble classifiers always more accurate? If so, why?\n",
    "\n",
    "Ensemble classifiers are always more accuracte when compared with individual models,because, an ensemble method is a technique that combines the predictions from multiple machine learning algorithms together to make more accurate predictions than any individual model,instead of creating a single model they create mulitple models and predict the values based on aggregating all the outputs,they generalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How do ensemble methods work for regression problems?\n",
    "\n",
    "For regression problems, ensemble method will create different models, all models will be different from each other and their observations would also be different, the predicted value is obtained by averaging the ouputs from the different models created by ensemble technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Explain how bagging methods work. What are its advantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging (stands for Bootstrap Aggregating) is a way to decrease the variance of your prediction by generating additional data for training from your original dataset using combinations with repetitions to produce multisets of the same size as the original data. bagging methods build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction.\n",
    "1. resamples training data to get M subsets (bootstrapping); \n",
    "2. trains M classifiers(same algorithm) based on M datasets(different samples)\n",
    "3. final classifier combines M outputs by voting\n",
    "\n",
    "These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm.\n",
    "\n",
    "As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).\n",
    "\n",
    "an example is random forest, which develop fully grown trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Explain how gradient boosting works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting builds the model in a sequential way. Gradient tree boosting is similar to AdaBoost, but instead of looking only at where it has failed, it also draws your attention to how much it has failed.\n",
    "\n",
    "- Each model is fit on a modified version of original data (original data is replaced with the x values and residuals from previous model. By fitting new models to the residuals, the overall model gradually improves in areas where residuals are initially high. The main idea behind the algorithm is to iteratively find new trees that minimize loss function—a measure of telling how bad the model is. This function has to be differentiable, and it’s selected based on the problem that needs solving.This function has to be differentiable (smooth, continuous, within limits), and it’s selected based on the problem that needs solving.For classification problems, we usually use the log loss function, which is simply the negative mean of log-probabilities where sample xi is classified as its label yi: Knowing the loss value, we can calculate the so-called “pseudo-residuals.” The greater the residual, the bigger the mistake. Pseudo-residuals are then used instead of labels when training a new tree.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Read the glass dataset using pandas. Build a classifier to classify the type of glass using:\n",
    "    1. A random forest classifier \n",
    "    2. Adaboost algorithm\n",
    "    3. Compare results from both algorithms and comment on their respective accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1      2     3     4      5     6     7    8    9   10\n",
       "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
       "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
       "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
       "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
       "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('glass.data',header=-1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['Id','RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      0\n",
       "Na      0\n",
       "Mg      0\n",
       "Al      0\n",
       "Si      0\n",
       "K       0\n",
       "Ca      0\n",
       "Ba      0\n",
       "Fe      0\n",
       "Type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      float64\n",
       "Na      float64\n",
       "Mg      float64\n",
       "Al      float64\n",
       "Si      float64\n",
       "K       float64\n",
       "Ca      float64\n",
       "Ba      float64\n",
       "Fe      float64\n",
       "Type      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type=df.Type.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Type',axis=1)\n",
    "Y = df.iloc[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample,x_test,y_sample,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_sample,y_sample,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. A random forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Adaboost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abcl = AdaBoostClassifier(n_estimators=50)\n",
    "abcl = abcl.fit(x_train, y_train)\n",
    "\n",
    "test_pred = abcl.predict(x_test)\n",
    "abcl.fit(x_train,y_train)\n",
    "abcl.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy in\n",
      "Train 1.0\n",
      "Valid 0.8222222222222222\n",
      "Test 0.8\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "Accuracy in\n",
      "Train 0.5192307692307693\n",
      "Valid 0.4444444444444444\n",
      "Test 0.4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest:')\n",
    "print('Accuracy in')\n",
    "print('Train',rf.score(x_train,y_train))\n",
    "print('Valid',rf.score(x_val,y_val))\n",
    "print('Test',rf.score(x_test,y_test))\n",
    "print('\\n')\n",
    "print('AdaBoost:')\n",
    "print('Accuracy in')\n",
    "print('Train',abcl.score(x_train,y_train))\n",
    "print('Valid',abcl.score(x_val,y_val))\n",
    "print('Test',abcl.score(x_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare results from both algorithms and comment on their respective accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Performs better than Ada boost as we can see from the above observation, random forest has an accuracy of 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Compare the relative strengths of Bagging vs Boosting. In what situation would one be preferred over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging:\n",
    "\n",
    "- parallel ensemble\n",
    "- aim to decrease variance, not bias\n",
    "- suitable for high variance low bias models (complex models)\n",
    "- an example of a tree based method is random forest, which develop fully grown trees \n",
    "\n",
    "Boosting:\n",
    "\n",
    "- sequential ensemble\n",
    "- aim to decrease bias, not variance\n",
    "- suitable for low variance high bias models\n",
    "- an example of a tree based method is gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what situation would one be preferred over the other? \n",
    "\n",
    "For complex models bagging is the better option and for simple models(which has weak learners) boosting is the better option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. The Climate model simulation crashes dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. \n",
    "    1. Use an ensemble classifier to predict the simulation outcomes (fail or succeed). Try a bagging as well as boosting classifier. Which type of model performs better?\n",
    "    2. What are the most important factors affecting simulation crashes in climate model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Use an ensemble classifier to predict the simulation outcomes (fail or succeed). Try a bagging as well as boosting classifier. Which type of model performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('pop_failures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869090703</td>\n",
       "      <td>0.997518496</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914343667</td>\n",
       "      <td>0.845247142</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995161</td>\n",
       "      <td>0.718441133</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761658752</td>\n",
       "      <td>0.362750561</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349434</td>\n",
       "      <td>0.650222833</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study  Run  vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  vconst_7  \\\n",
       "0      1    1     0.859036  0.927825  0.252866  0.298838  0.170521  0.735936   \n",
       "1      1    2     0.606041  0.457728  0.359448  0.306957  0.843331  0.934851   \n",
       "2      1    3     0.997600  0.373238  0.517399  0.504993  0.618903  0.605571   \n",
       "3      1    4     0.783408  0.104055  0.197533  0.421837  0.742056  0.490828   \n",
       "4      1    5     0.406250  0.513199  0.061812  0.635837  0.844798  0.441502   \n",
       "\n",
       "    ah_corr  ah_bolus   ...     efficiency_factor  tidal_mix_max  \\\n",
       "0  0.428325  0.567947   ...              0.245675       0.104226   \n",
       "1  0.444572  0.828015   ...              0.616870       0.975786   \n",
       "2  0.746225  0.195928   ...              0.679355       0.803413   \n",
       "3  0.005525  0.392123   ...              0.471463       0.597879   \n",
       "4  0.191926  0.487546   ...              0.551543       0.743877   \n",
       "\n",
       "   vertical_decay_scale convect_corr bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0           0.869090703  0.997518496     0.448620         0.307522   \n",
       "1           0.914343667  0.845247142     0.864152         0.346713   \n",
       "2           0.643995161  0.718441133     0.924775         0.315371   \n",
       "3           0.761658752  0.362750561     0.912819         0.977971   \n",
       "4           0.312349434  0.650222833     0.522261         0.043545   \n",
       "\n",
       "   bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  outcome  \n",
       "0        0.858310          0.796997  0.869893        0  \n",
       "1        0.356573          0.438447  0.512256        1  \n",
       "2        0.250642          0.285636  0.365858        1  \n",
       "3        0.845921          0.699431  0.475987        1  \n",
       "4        0.376660          0.280098  0.132283        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Study                   0\n",
       "Run                     0\n",
       "vconst_corr             0\n",
       "vconst_2                0\n",
       "vconst_3                0\n",
       "vconst_4                0\n",
       "vconst_5                0\n",
       "vconst_7                0\n",
       "ah_corr                 0\n",
       "ah_bolus                0\n",
       "slm_corr                0\n",
       "efficiency_factor       0\n",
       "tidal_mix_max           0\n",
       "vertical_decay_scale    0\n",
       "convect_corr            0\n",
       "bckgrnd_vdc1            0\n",
       "bckgrnd_vdc_ban         0\n",
       "bckgrnd_vdc_eq          0\n",
       "bckgrnd_vdc_psim        0\n",
       "Prandtl                 0\n",
       "outcome                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Study                     int64\n",
       "Run                       int64\n",
       "vconst_corr             float64\n",
       "vconst_2                float64\n",
       "vconst_3                float64\n",
       "vconst_4                float64\n",
       "vconst_5                float64\n",
       "vconst_7                float64\n",
       "ah_corr                 float64\n",
       "ah_bolus                float64\n",
       "slm_corr                float64\n",
       "efficiency_factor       float64\n",
       "tidal_mix_max           float64\n",
       "vertical_decay_scale     object\n",
       "convect_corr             object\n",
       "bckgrnd_vdc1            float64\n",
       "bckgrnd_vdc_ban         float64\n",
       "bckgrnd_vdc_eq          float64\n",
       "bckgrnd_vdc_psim        float64\n",
       "Prandtl                 float64\n",
       "outcome                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>0.657136</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.411950</td>\n",
       "      <td>0.087780</td>\n",
       "      <td>0.356289</td>\n",
       "      <td>0.480204</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280546</td>\n",
       "      <td>0.384117</td>\n",
       "      <td>8        0.885948282473772</td>\n",
       "      <td>4      0.7684815695121264</td>\n",
       "      <td>0.459479</td>\n",
       "      <td>0.334482</td>\n",
       "      <td>0.573002</td>\n",
       "      <td>0.610183</td>\n",
       "      <td>0.737706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>0.915894</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.518947</td>\n",
       "      <td>0.090622</td>\n",
       "      <td>0.336981</td>\n",
       "      <td>0.893576</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798108</td>\n",
       "      <td>0.353546</td>\n",
       "      <td>7       0.0447958718286827</td>\n",
       "      <td>2      0.9908996256417595</td>\n",
       "      <td>0.347027</td>\n",
       "      <td>0.512499</td>\n",
       "      <td>0.810549</td>\n",
       "      <td>0.593332</td>\n",
       "      <td>0.142565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.941185</td>\n",
       "      <td>0.769245</td>\n",
       "      <td>0.950776</td>\n",
       "      <td>0.189406</td>\n",
       "      <td>0.112743</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.527096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193103</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>1         0.10150603622379</td>\n",
       "      <td>2      0.5488780750505006</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.198811</td>\n",
       "      <td>0.867108</td>\n",
       "      <td>0.461632</td>\n",
       "      <td>0.652817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.779287</td>\n",
       "      <td>0.867468</td>\n",
       "      <td>0.704820</td>\n",
       "      <td>0.983282</td>\n",
       "      <td>0.420303</td>\n",
       "      <td>0.710612</td>\n",
       "      <td>0.174746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.436714</td>\n",
       "      <td>7        0.690131570445373</td>\n",
       "      <td>7      0.8251331410254352</td>\n",
       "      <td>0.981656</td>\n",
       "      <td>0.113193</td>\n",
       "      <td>0.364799</td>\n",
       "      <td>0.201469</td>\n",
       "      <td>0.536535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.608075</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.598264</td>\n",
       "      <td>0.794771</td>\n",
       "      <td>0.145680</td>\n",
       "      <td>0.378183</td>\n",
       "      <td>0.461948</td>\n",
       "      <td>0.425291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480938</td>\n",
       "      <td>0.307816</td>\n",
       "      <td>3        0.231637950383851</td>\n",
       "      <td>1      0.4641517308579448</td>\n",
       "      <td>0.583558</td>\n",
       "      <td>0.969365</td>\n",
       "      <td>0.464331</td>\n",
       "      <td>0.760344</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Study  Run  vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  \\\n",
       "535      3  176     0.657136  0.489375  0.133713  0.411950  0.087780   \n",
       "536      3  177     0.915894  0.842720  0.518947  0.090622  0.336981   \n",
       "537      3  178     0.478600  0.941185  0.769245  0.950776  0.189406   \n",
       "538      3  179     0.007793  0.779287  0.867468  0.704820  0.983282   \n",
       "539      3  180     0.608075  0.031556  0.598264  0.794771  0.145680   \n",
       "\n",
       "     vconst_7   ah_corr  ah_bolus   ...     efficiency_factor  tidal_mix_max  \\\n",
       "535  0.356289  0.480204  0.029678   ...              0.280546       0.384117   \n",
       "536  0.893576  0.978703  0.674868   ...              0.798108       0.353546   \n",
       "537  0.112743  0.745645  0.527096   ...              0.193103       0.829563   \n",
       "538  0.420303  0.710612  0.174746   ...              0.761134       0.436714   \n",
       "539  0.378183  0.461948  0.425291   ...              0.480938       0.307816   \n",
       "\n",
       "           vertical_decay_scale               convect_corr bckgrnd_vdc1  \\\n",
       "535  8        0.885948282473772  4      0.7684815695121264     0.459479   \n",
       "536  7       0.0447958718286827  2      0.9908996256417595     0.347027   \n",
       "537  1         0.10150603622379  2      0.5488780750505006     0.381966   \n",
       "538  7        0.690131570445373  7      0.8251331410254352     0.981656   \n",
       "539  3        0.231637950383851  1      0.4641517308579448     0.583558   \n",
       "\n",
       "     bckgrnd_vdc_ban  bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  outcome  \n",
       "535         0.334482        0.573002          0.610183  0.737706        1  \n",
       "536         0.512499        0.810549          0.593332  0.142565        0  \n",
       "537         0.198811        0.867108          0.461632  0.652817        1  \n",
       "538         0.113193        0.364799          0.201469  0.536535        1  \n",
       "539         0.969365        0.464331          0.760344  0.762439        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.head(310) # the given data was giving an error as there is a difference in format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data,kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='outcome',axis=1)\n",
    "Y = data.iloc[:,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample,x_test,y_sample,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_sample,y_sample,test_size=0.3,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": sp_randint(2, 15),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "samples = 10  # number of random samples \n",
    "randomCV = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=samples) #default cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "randomCV.fit(X, Y)\n",
    "\n",
    " \n",
    "print(randomCV.best_params_)\n",
    "#print(randomCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9242424242424242"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap= False, criterion= 'entropy', max_depth= 9, min_samples_leaf= 3, min_samples_split= 3)\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl = BaggingClassifier(n_estimators=100, max_samples=.50 , oob_score=True , random_state=1)\n",
    "\n",
    "bgcl = bgcl.fit(x_train,y_train)\n",
    "bgcl.fit(x_train,y_train)\n",
    "bgcl.score(x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(max_depth=6,random_state=1)\n",
    "gb.fit(x_train,y_train)\n",
    "gb.score(x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abcl = AdaBoostClassifier(n_estimators=50)\n",
    "abcl.fit(x_train,y_train)\n",
    "abcl.score(x_val,y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier:\n",
      "Train 0.9735099337748344\n",
      "Valid 0.9545454545454546\n",
      "Test 0.9139784946236559\n",
      "\n",
      "\n",
      "\n",
      "Gradient Descent:\n",
      "Train 1.0\n",
      "Valid 0.9090909090909091\n",
      "Test 0.9032258064516129\n",
      "\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Train 1.0\n",
      "Valid 0.9242424242424242\n",
      "Test 0.9247311827956989\n",
      "\n",
      "\n",
      "\n",
      "AdaBoostClassifier:\n",
      "Train 1.0\n",
      "Valid 0.9090909090909091\n",
      "Test 0.8924731182795699\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Classifier:')\n",
    "print('Train',bgcl.score(x_train,y_train))\n",
    "print('Valid',bgcl.score(x_val,y_val))\n",
    "print('Test',bgcl.score(x_test,y_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Gradient Descent:')\n",
    "print('Train',gb.score(x_train,y_train))\n",
    "print('Valid',gb.score(x_val,y_val))\n",
    "print('Test',gb.score(x_test,y_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "print('Random Forest:')\n",
    "print('Train',rf.score(x_train,y_train))\n",
    "print('Valid',rf.score(x_val,y_val))\n",
    "print('Test',rf.score(x_test,y_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('AdaBoostClassifier:')\n",
    "print('Train',abcl.score(x_train,y_train))\n",
    "print('Valid',abcl.score(x_val,y_val))\n",
    "print('Test',abcl.score(x_test,y_test))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above observations the Random Forest Classifier performs better than Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01477176, 0.21334562, 0.16015619, 0.0347506 ,\n",
       "       0.09490379, 0.02385063, 0.04577904, 0.03321241, 0.0147966 ,\n",
       "       0.02324744, 0.04214077, 0.01458442, 0.02376597, 0.10350005,\n",
       "       0.03925312, 0.04073552, 0.03274734, 0.03760614, 0.00685259])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. What are the most important factors affecting simulation crashes in climate model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vconst_corr             0.213346\n",
      "vconst_2                0.160156\n",
      "convect_corr            0.103500\n",
      "vconst_4                0.094904\n",
      "vconst_7                0.045779\n",
      "efficiency_factor       0.042141\n",
      "bckgrnd_vdc_ban         0.040736\n",
      "bckgrnd_vdc1            0.039253\n",
      "bckgrnd_vdc_psim        0.037606\n",
      "vconst_3                0.034751\n",
      "ah_corr                 0.033212\n",
      "bckgrnd_vdc_eq          0.032747\n",
      "vconst_5                0.023851\n",
      "vertical_decay_scale    0.023766\n",
      "slm_corr                0.023247\n",
      "ah_bolus                0.014797\n",
      "Run                     0.014772\n",
      "tidal_mix_max           0.014584\n",
      "Prandtl                 0.006853\n",
      "Study                   0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (pd.Series(rf.feature_importances_, index = X.columns).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important features are:\n",
    "\n",
    "vconst_corr             \n",
    "vconst_2                \n",
    "convect_corr            \n",
    "vconst_4                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
